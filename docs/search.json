[
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "My Blog",
    "section": "",
    "text": "Advanced Visualizations\n\n\nAdvanced visualization displaying each countries interest in science and action to learn more about science.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Dashboards (Static)\n\n\nStatic dashboard visualizing each country’s trust in science and knowledge of science.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Dashboards (Dynamic)\n\n\nDynamic dashboard visualizing each country’s trust in science and knowledge of science.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Effecient Functions\n\n\nFunctions used for fitting a model while removing outliers and imputing data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJSON Data & APIs\n\n\nPulling JSON data on the ISS from an API.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWebscraping\n\n\nWebscraping information about cheese.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative Art\n\n\nGenerative art created in R.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/Webscraping/index.html",
    "href": "portfolio/Webscraping/index.html",
    "title": "Webscraping",
    "section": "",
    "text": "Functions for pulling all cheeses\nThese functions are used to pull cheese information from the cheese.com website. get_text_from_page is used to get the names of each cheese, get_url_from_page is used to get the url for each cheese, and get_image_from_page is used to get the image for each cheese. scrape page is then used to call the other functions to get the information for all the cheeses.\n\nget_text_from_page &lt;- function(page, css_selector) {\n    \n  page %&gt;%\n    html_elements(css_selector) %&gt;%\n    html_text(trim = T)\n}\n\nget_url_from_page &lt;- function(page, css_selector) {\n    \n  page %&gt;%\n    html_elements(css_selector) %&gt;%\n    html_attr(\"href\")\n}\n\nget_image_from_page &lt;- function(page, css_selector) {\n    \n  page %&gt;%\n    html_elements(css_selector) %&gt;%\n    html_attr(\"src\")\n}\n\nscrape_page &lt;- function(url) {\n    \n    # 1 second crawl delay\n    Sys.sleep(1)\n    \n    # Read the page\n    page &lt;- read_html(url)\n    \n    # Grab elements from the page\n    cheese_names &lt;- get_text_from_page(page, \".product-item\")\n    cheese_url &lt;- get_url_from_page(page, \".product-item a\")\n    cheese_image &lt;- get_image_from_page(page, \".product-item img\")\n    \n    # Clean cheese names\n    cheese_names &lt;- cheese_names %&gt;%\n      trimws()\n    \n    cheese_names &lt;- ifelse(\n      str_detect(cheese_names, \"Stores &gt;\"),\n      str_trim(str_extract(cheese_names, \"[^\\n]+$\")),\n      cheese_names\n      )\n    \n    # Full cheese URL\n    base_url &lt;- \"https://www.cheese.com\"\n    cheese_url &lt;- paste0(base_url, cheese_url)\n    cheese_url &lt;- unique(cheese_url[!grepl(\"store\", cheese_url)]) #remove store links + duplicates\n    \n    # Find cheeses with image\n    has_image &lt;- ifelse(grepl(\"static\", cheese_image), \"No\", \"Yes\")\n    \n    #Put page elements into a dataframe\n    cheeses &lt;- data.frame(\n      cheese = cheese_names,\n      url = cheese_url,\n      image = has_image\n    )\n    \n    return(cheeses)\n}\n\n\n\nPulling all cheeses\n\nbase_url &lt;- \"https://www.cheese.com/alphabetical/?per_page=100\"\n\nurls_all_pages &lt;- c(str_c(base_url,\n                          \"&page=\",\n                          1:21)\n                     )\n\nall_pages &lt;- map(urls_all_pages, scrape_page)\n\nall_cheeses &lt;- bind_rows(all_pages)\n\nhead(all_cheeses) %&gt;%\n  gt()\n\n\n\n\n\n\n\ncheese\nurl\nimage\n\n\n\n\n2 Year Aged Cumin Gouda\nhttps://www.cheese.com/2-year-aged-cumin-gouda/\nYes\n\n\n3-Cheese Italian Blend\nhttps://www.cheese.com/3-cheese-italian-blend/\nNo\n\n\n30 Month Aged Parmigiano Reggiano\nhttps://www.cheese.com/30-month-aged-parmigiano-reggiano-150g/\nYes\n\n\n3yrs Aged Vintage Gouda\nhttps://www.cheese.com/3yrs-aged-vintage-gouda/\nYes\n\n\nAarewasser\nhttps://www.cheese.com/aarewasser/\nYes\n\n\nAbbaye de Belloc\nhttps://www.cheese.com/abbaye-de-belloc/\nYes\n\n\n\n\n\n\n\n\n\nFunctions for pulling detailed cheese info\nThese functions are used to pull the detailed cheese information from the urls from the above function. clean_info is used to clean the information that gets scraped from the website and is called by scrape_cheese to pull info on milk, country, family, type, and flavor.\n\nclean_info &lt;- function(text, fallback) {\n  if (length(text) == 0) {\n    return(fallback)\n  } else {\n    cleaned &lt;- sub(\".*?:\\\\s*\", \"\", text) # Extract everything after \": \"\n    return(trimws(cleaned))\n  }\n}\n\nscrape_cheese &lt;- function(url) {\n    \n    # 1 second crawl delay\n    Sys.sleep(1)\n    \n    # Read the page\n    page &lt;- read_html(url)\n    \n    # Grab elements from the page\n    milk &lt;- get_text_from_page(page, \".summary_milk\")\n    country &lt;- get_text_from_page(page, \".summary_country\")\n    family &lt;- get_text_from_page(page, \".summary_family\")\n    type &lt;- get_text_from_page(page, \".summary_moisture_and_type\")\n    flavor &lt;- get_text_from_page(page, \".summary_taste\")\n    \n    # Clean elements\n    milk &lt;- clean_info(milk, \"No milk information available\")\n    country &lt;- clean_info(country, \"No country information available\")\n    family &lt;- clean_info(family, \"No family information available\")\n    type &lt;- clean_info(type, \"No type information available\")\n    flavor &lt;- clean_info(flavor, \"No flavor information available\")\n    \n    # Puts elements into data frame\n    cheese &lt;- data.frame(\n      milk = milk,\n      country = country,\n      family = family,\n      type = type,\n      flavor = flavor\n    )\n}\n\n\n\nPulling detailed cheese info\n\nsampled_cheeses &lt;- all_cheeses %&gt;%\n  sample_n(10)\n\ndetailed_cheeses &lt;- sampled_cheeses$url %&gt;%\n  map_df(scrape_cheese)\n\nfinal_cheese_info &lt;- bind_cols(\n  sampled_cheeses %&gt;% select(cheese),\n  detailed_cheeses\n)\n\nfinal_cheese_info %&gt;%\n  gt()\n\n\n\n\n\n\n\ncheese\nmilk\ncountry\nfamily\ntype\nflavor\n\n\n\n\nClonmore\nMade from pasteurized goat's milk\nIreland\nGouda\nhard, artisan\nearthy, mild, milky, nutty, smooth, sweet, tangy\n\n\nCarrick\nMade from unpasteurized cow's milk\nScotland\nNo family information available\nhard, organic\ncitrusy\n\n\nLe Sanérac\nMade from unpasteurized cow's milk\nFrance\nNo family information available\nsemi-hard, artisan\nNo flavor information available\n\n\nSartori Reserve Basil & Olive Oil Asiago\nMade from pasteurized cow's milk\nUnited States\nNo family information available\nhard, artisan\nherbaceous, nutty, savory, sweet\n\n\nSartori Raspberry BellaVitano\nMade from pasteurized cow's milk\nUnited States\nNo family information available\nhard, artisan\nfruity, nutty, sweet\n\n\nNettles Gone Wild\nMade from pasteurized goat's milk\nItaly\nNo family information available\nsoft, artisan, soft-ripened\nearthy, full-flavored\n\n\nAlex James Co. No 1 Cheddar\nMade from cow's milk\nUnited Kingdom\nNo family information available\nhard\nsweet\n\n\nKäse Mit Schweizer Trüffeln\nMade from unpasteurized cow's milk\nSwitzerland\nSwiss Cheese\nsemi-soft, artisan\ncreamy\n\n\nWestray Wife\nMade from pasteurized cow's milk\nScotland\nNo family information available\nfirm\ngarlicky, grassy, nutty, salty, savory, umami\n\n\nTilly Whim\nMade from unpasteurized cow's milk\nEngland, Great Britain and United Kingdom\nNo family information available\nsemi-soft, artisan\nearthy, full-flavored"
  },
  {
    "objectID": "portfolio/Static/index.html",
    "href": "portfolio/Static/index.html",
    "title": "Quarto Dashboards (Static)",
    "section": "",
    "text": "This static dashboard displays the percentage of people who reported having trust and knowledge in science in each country. On the Plots page, there is a scatter plot showing the trust and knowledge levels. On the right side of the page, there are statistics showing the average knowledge, average trust, and the correlation between trust and knowledge. Finally, there are two tables to choose between that show the countries with the highest and lowest trust-to-knowledge ratios.\nThe maps page has two maps to choose from, one for knowledge and one for trust. These show world maps that are colored by the knowledge or trust levels and the user and hover over the countries to see what their levels are."
  },
  {
    "objectID": "portfolio/Static/index.html#my-shiny-dashboard",
    "href": "portfolio/Static/index.html#my-shiny-dashboard",
    "title": "Quarto Dashboards (Static)",
    "section": "My Shiny Dashboard",
    "text": "My Shiny Dashboard"
  },
  {
    "objectID": "portfolio/Generative Art/index.html",
    "href": "portfolio/Generative Art/index.html",
    "title": "Generative Art",
    "section": "",
    "text": "In Fragmented Orbit, the artist explores the delicate tension between order and disarray. Using programmatic motion and layered forms, the piece traces the outline of a circle—traditionally a symbol of unity—only to disrupt it with sharp, scattered bars of warm and dark tones. The interplay of deep maroons and bright amber suggests an atmospheric transition, like a sunrise through fractured glass. It evokes a moment caught between movement and stillness, precision and spontaneity—a quiet chaos rendered in digital form."
  },
  {
    "objectID": "portfolio/Generative Art/index.html#function-for-fragmented-orbit",
    "href": "portfolio/Generative Art/index.html#function-for-fragmented-orbit",
    "title": "Generative Art",
    "section": "Function for Fragmented Orbit",
    "text": "Function for Fragmented Orbit\n\npolar_art_dual &lt;- function(seed, n, palette_top, palette_bottom) {\n  set.seed(seed)\n  \n  #data generation\n  dat &lt;- tibble(\n    x0 = runif(n, 0, 360), #start angle\n    y0 = abs(rnorm(n, 1, 0.3)), #start radius\n    x1 = x0 + runif(n, -10, 10), #end angle\n    y1 = y0 + rnorm(n, 0, 0.3), #end radius\n    shade = rnorm(n),\n    size = abs(rnorm(n, 1, 0.5))\n  ) %&gt;%\n    mutate( # keep angles between 0 and 360\n      x0 = x0 %% 360,\n      x1 = x1 %% 360,\n      group = if_else( # Define top as angles between 270-360 or 0-90 degrees\n        (x0 &gt;= 270 | x0 &lt;= 90), \"top\", \"bottom\"\n      )\n    )\n  \n  # break up data to top and bottom\n  dat_top &lt;- dat %&gt;% filter(group == \"top\")\n  dat_bottom &lt;- dat %&gt;% filter(group == \"bottom\")\n  \n  #plot\n  ggplot() +\n    \n    #top data\n    geom_segment(\n      data = dat_top,\n      aes(x = x0, y = y0, xend = x1, yend = y1, colour = shade, linewidth = size),\n      show.legend = FALSE\n    ) +\n    scale_colour_gradientn(colours = palette_top) +\n    ggnewscale::new_scale_color() +\n    \n    #bottom data\n    geom_segment(\n      data = dat_bottom,\n      aes(x = x0, y = y0, xend = x1, yend = y1, colour = shade, linewidth = size),\n      show.legend = FALSE\n    ) +\n    scale_colour_gradientn(colours = palette_bottom) +\n    \n    coord_polar(start = 0) +\n    scale_x_continuous(limits = c(0, 360), expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_size(range = c(0, 5)) +\n    theme_void()\n}"
  },
  {
    "objectID": "portfolio/Generative Art/index.html#functions-for-viscous-drift",
    "href": "portfolio/Generative Art/index.html#functions-for-viscous-drift",
    "title": "Generative Art",
    "section": "Functions for Viscous Drift",
    "text": "Functions for Viscous Drift\n\n# Random palette - returns hex values\nsample_lava_palette &lt;- function(n = 256) {\n  hues &lt;- sort(runif(n))\n  sats &lt;- runif(n, 0.7, 1) #saturation\n  vals &lt;- runif(n, 0.8, 1) #brightness\n  hsv(hues, sats, vals)\n}\n\n# Single frame generator with time offset\nlava_frame &lt;- function(frame, pixels = 400, speed = 100, freq = 3) {\n  z_offset &lt;- frame / speed  # change speed of animation - divide by larger # to slow\n  \n  # create grid of pixels\n  grid &lt;- long_grid(\n    x = seq(0, 1, length.out = pixels),\n    y = seq(0, 1, length.out = pixels)\n  ) |&gt;\n    mutate(\n      paint = fracture(\n        x = x,\n        y = y,\n        z = z_offset,\n        noise = gen_simplex, # simplex noise generator to look like lava lamp\n        fractal = fbm, # fractal Brownian motion\n        octaves = 1, # can't notice changes when adjusting\n        frequency = freq # changes number of blobs, want to keep low\n      ),\n      paint = normalise(paint)\n    ) |&gt;\n    as.array(value = paint)\n  \n  # generates color palette\n  lava_palette &lt;- sample_lava_palette(256)\n  \n  # apply shading\n  img &lt;- height_shade(grid, texture = lava_palette)\n  \n  image_read(img)\n}\n\n#gif function\nmake_lava_gif &lt;- function(frames = 40, fps = 1, speed = 100, freq = 3) {\n  \n  # check that fps is a factor of 100 (needed for function)\n  if (100 %% fps != 0){\n    stop(\"fps must be a factor of 100\")\n  }\n  \n  # animates frames\n  images &lt;- map(1:frames, ~ lava_frame(.x, speed = speed, freq = freq))\n  animation &lt;- image_animate(image_join(images), fps = fps)\n  \n  return(animation)\n}"
  },
  {
    "objectID": "portfolio/Dynamic/index.html",
    "href": "portfolio/Dynamic/index.html",
    "title": "Quarto Dashboards (Dynamic)",
    "section": "",
    "text": "This dynamic dashboard displays the percentage of people who reported having trust and knowledge in science in each country. On the Plots page, there is a scatter plot showing the trust and knowledge levels. On the right side of the page, there are statistics showing the average knowledge, average trust, and the correlation between trust and knowledge. Finally, there are two tables to choose between that show the countries with the highest and lowest trust-to-knowledge ratios.\nOn the left side, there is a sidebar that lets the user subset the data reported. There are check boxes that allow the user to select which regions they want to see in the graphics. There are also two sliders that allow the user to subset the data based on the range of the knowledge and trust levels.\nThe maps page has two maps to choose from, one for knowledge and one for trust. These show world maps that are colored by the knowledge or trust levels and the user and hover over the countries to see what their levels are."
  },
  {
    "objectID": "portfolio/Dynamic/index.html#my-shiny-dashboard",
    "href": "portfolio/Dynamic/index.html#my-shiny-dashboard",
    "title": "Quarto Dashboards (Dynamic)",
    "section": "My Shiny Dashboard",
    "text": "My Shiny Dashboard"
  },
  {
    "objectID": "portfolio/JSON Data & APIs/index.html",
    "href": "portfolio/JSON Data & APIs/index.html",
    "title": "JSON Data & APIs",
    "section": "",
    "text": "This function is used to pull the times the ISS passes a set lat/long in the next 72 hours. The function is used to pull the times for all US state capitals.\n\nget_city_info &lt;- function(lat, long) {\n  url &lt;- paste0(\"https://api.g7vrd.co.uk/v1/satellite-passes/25544/\",\n                lat, \"/\", long, \".json?hours=72\") # pulls by lat long, time set for 72 hours\n  \n  res &lt;- try(GET(url), silent = TRUE)\n  content &lt;- content(res, \"text\", encoding = \"UTF-8\")\n  json_data &lt;- fromJSON(content, flatten = TRUE)\n  return(json_data)\n}\n\nThe plot below shows the location for all US state capitals. If you hover over the spaceship logo, it will show the next time the ISS passes that location. If you click on the logo, it will show the times for the next 3 passes. Finally, the plot has lines connecting the capitals showing the chronological order of the next passes."
  },
  {
    "objectID": "portfolio/Visualizations/index.html",
    "href": "portfolio/Visualizations/index.html",
    "title": "Advanced Visualizations",
    "section": "",
    "text": "This visualization displays the percentage of people who reported having interest in science and having sought information in the last 30 days about science in each country. The user can hover over points in the plot to view the values and the country name. The dotted lines on the graph are the median values.\n\n\n\n\n\n\nThis visualization displays the percentage of people who believe that vaccines are safe, broken down by region. The user can hover over points in the plot to view the values and the country name. The dotted lines on the graph are the region’s median values."
  },
  {
    "objectID": "portfolio/Writing Efficient Functions/index.html",
    "href": "portfolio/Writing Efficient Functions/index.html",
    "title": "Writing Effecient Functions",
    "section": "",
    "text": "Remove Outliers\nThis function takes in a data set, variables, and a standard deviation threshold and removes the outliers from the specified variables. The default standard deviation threshold is set at 3. The function has a built in warning if a categorical variable is input and a stop if no numeric variables are input. The final output of the function is a data set with the rows with outliers removed.\n\nremove_outliers &lt;- function(data, ..., sd_thresh = 3){\n  \n  # grabs variables in ... and converts to character\n  vars &lt;- quos(...)  #variables in ...\n  var_names &lt;- sapply(vars, as_name) #converts vars to character\n\n  # finds any non-numeric vars and gives warning message\n  non_numeric_vars &lt;- var_names[!sapply(data[var_names], is.numeric)]\n  \n  if (length(non_numeric_vars) &gt; 0) {\n    warning(\"The following variables are categorical and will be ignored: \", \n            paste(non_numeric_vars, collapse = \", \"))\n  }\n\n  # finds numeric vars and only keeps rows that aren't outliers\n  numeric_vars &lt;- var_names[sapply(data[var_names], is.numeric)]\n\n  if (length(numeric_vars) == 0) {\n    stop(\"No numeric variables provided for outlier detection.\")\n  }\n\n  z_scores &lt;- data %&gt;%\n    select(all_of(numeric_vars)) %&gt;%\n    mutate(across(everything(), scale))\n\n  keep_rows &lt;- apply(abs(z_scores), 1, function(row) all(row &lt; sd_thresh))\n\n  # return final data set\n  return(data[keep_rows, ])\n}\n\n\n\nImpute Missing\nThis function takes in a data set, variables, and an imputation function and imputes missing values from the specified variables. The default imputation function is using the mean. The function has a built in warning if a categorical variable is input. The final output of the function is a data set with missing numeric values imputed.\n\nimpute_missing &lt;- function(data, ..., impute_fun = mean){\n  \n  # grabs variables in ... and converts to character\n  vars &lt;- enquos(...) #variables in ...\n  var_names &lt;- sapply(vars, as_name) #converts vars to character\n  \n  impute_fun &lt;- match.fun(impute_fun) #function from impute_fun\n\n  # finds any non-numeric vars and gives warning message\n  non_numeric_vars &lt;- var_names[!sapply(data[, var_names], is.numeric)]\n  \n  if (length(non_numeric_vars) &gt; 0) {\n    warning(\"The following variables are not numeric and will be skipped: \", \n            paste(non_numeric_vars, collapse = \", \"))\n  }\n  \n  # Apply imputation only to numeric columns\n  data %&gt;%\n    mutate(across(\n      all_of(var_names),\n      ~ if (is.numeric(.)) {replace_na(., impute_fun(., na.rm = TRUE))} else {.}\n    ))\n}\n\n\n\nFit Model\nFinally, this function takes in a data set, model formula, set of variables, a true or false for removing outliers and imputing, an imputation function, and a standard deviation threshold, and fits a linear regression model. The function first calls the previous two functions to remove outliers or impute if either of those are set to true. Once the data is cleaned, the function fits and returns the linear regression model.\n\nfit_model &lt;- function(data, mod_formula, ...,\n                      remove_outliers = FALSE, impute_missing = FALSE,\n                      impute_fun = mean, sd_thresh = 3) {\n  \n  vars &lt;- enquos(...) #variables in ...\n  \n  # Remove outliers\n  if (remove_outliers) {\n    data &lt;- remove_outliers(data, !!!vars, sd_thresh = sd_thresh)\n  }\n\n  # Impute\n  if (impute_missing) {\n    data &lt;- impute_missing(data, !!!vars, impute_fun = impute_fun)\n  }\n\n  # Fit model\n  model &lt;- lm(mod_formula, data = data)\n  return(model)\n}"
  }
]